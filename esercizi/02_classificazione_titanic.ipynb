{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Dataset - Classificazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo notebook utilizzeremo il dataset `Titanic` che contiene alcune informazioni relative ai passeggeri del Titanic, nave tristemente famosa in quanto è affondata durante il viaggio di inaugurazione causando centinaia di morti. \n",
    "\n",
    "Utilizzeremo questo dataset per sviluppare un modello di **classificazione**, che ci permetterà di prevedere la sopravvivenza o meno dei passeggeri. Nella prima sezione vedremo come implementare un Albero decisionale per la classificazione. Nella seconda vedremo altri modelli di classificazione un po' più complessi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: scorrendo il notebook noterai che ci sono alcune celle di codice che contengono puntini (...), quelle sono le parti che dovrai completare aiutandoti con le esercitazioni che abbiamo svolto durante le lezioni e con le presentazioni che avete seguito. Altre celle sono invece già completate e dovrai solo cliccare 'run' per studiarne l'output. Troverai anche alcune domande che ti guideranno nella descrizione e nell'analisi che svolgerai per il report finale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a> <br>\n",
    "\n",
    "# Indice\n",
    "1. [Pre-processing dei dati](#1)\n",
    "2. [Exploratory Data Analysis](#2)\n",
    "3. [Implementazione e valutazione del modello Decision Tree](#3)\n",
    "4. [Altri modelli di classificazione](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> <br>\n",
    "## 1. Pre-processing dei dati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo step fondamentale prima di applicare un modello di Machine Learning è quello di studiare le caratteristiche principali dei dati per renderli utilizzabili dal modello che sceglieremo. In questa sezione, metteremo in pratica le tecniche viste nelle precedenti lezioni per analizzare il dataset, in particolare dovremo:\n",
    "- caricare il dataset\n",
    "- estrarre le prime descrizioni generali (dimensione, tipo di dati, variabili, ...)\n",
    "- gestire i valori mancanti\n",
    "- gestire variabili categoriche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Caricamento del dataset e descrizione generale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento del dataset\n",
    "df = pd.read_csv('../data/Titanic_data.csv')\n",
    "\n",
    "# Stampa le prime dieci righe\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Che dimensione ha il dataset? Quante righe e quante colonne ha?\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quali sono i nomi delle variabili presenti nel dataset? I nomi delle variabili sono contenuti nella lista delle colonne del dataframe\n",
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il dataset contiene 8 variabili:\n",
    "\n",
    "1. **PassengerId**: ID del passeggero\n",
    "\n",
    "2. **Pclass**: classe del biglietto del passeggero passeggero (1 = prima classe, 2 = seconda classe, 3 = terza classe)\n",
    "\n",
    "3. **Name**: nome del passeggero\n",
    "\n",
    "4. **Sex**: sesso del passeggero\n",
    "\n",
    "5. **Age**:: età del passeggero\n",
    "\n",
    "6. **SibSp**: indica quanti fratelli/sorelle o mogli/spose il passeggero aveva sul Titanic\n",
    "\n",
    "7. **Parch**: indica quanti mamme/papà o figli il passeggero aveva sul Titanic\n",
    "\n",
    "8. **Ticket**: numero diel biglietto\n",
    "\n",
    "9. **Fare**: tariffa pagata dal passeggero\n",
    "\n",
    "10. **Cabin**: numero della cabina\n",
    "\n",
    "11. **Embarked**: porto d'imbarco del passegero (C = Cherbourg, Q = Queenstown, S = Southampton)\n",
    "\n",
    "12. **Survived**: indica se il passeggero è sopravvissuto o no (0 = No, 1 = Yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alcune informazioni importanti sul dataset (possiamo usare il metodo .info())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipo di dato in ogni colonna (possiamo usare il metodo .dtypes)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caratteristiche statistiche principali per le variabili numeriche\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Valori mancanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quanti valori nulli ci sono in ogni colonna?\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcoliamo la percentuale di dati mancanti per ogni variabile\n",
    "missing_values = df.isna().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "print(\"Missing Values and Percentages:\\n\", pd.DataFrame({\n",
    "    'Missing Count': missing_values,\n",
    "    'Percentage': missing_percentage\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Come gestiamo i valori nulli?\n",
    "# Ci sono vari metodi per gestire i dati mancanti: possiamo eliminare dal dataset le righe corrispondenti, sostituirli con un valore medio o con il valore mediano, ...\n",
    "# In questo caso, ci sono tre variabili che presentano dei valorinulli: Age, Cabin, Embarked.\n",
    "\n",
    "# Per quanto riguarda la variabile \"Cabin\", siccome oltre il 70% dei passeggeri presenti nel dataset hanno un valore nullo e\n",
    "# tale variabile non sembra essere correlata con la variabile survived, decidiamo di eliminare tutta la variabile dal dataset\n",
    "df.drop('Cabin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per quanto riguarda la variabile \"Age\" siccome c'è un numero considerevole di dati mancanti (quasi il 20%), \n",
    "# proviamo a sostituire tali valori mancanti con la mediana che è più robusta agli outlier rispetto alla media)\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infine, per quanto riguarda la variabile 'Embarked' siccome ci sono solo due valori mancanti li sostituiamo con la moda (valore più frequente)\n",
    "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Variabili categoriche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci sono tre variabili categoriche:\n",
    "- **Pclass**: Ordinale (1st, 2nd, 3rd class) -> non necessita di encoding in quanto i valori sono già numerici (1,2,3)\n",
    "- **Sex**: Nominale (Male, Female) -> Label Encoding (Male -> 0, Female-> 1)\n",
    "- **Embarked**: Nominale (C, Q, S) -> One-Hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding per 'Sex' (binaria -> 'male': 0, 'female': 1)\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1}) # Inserisci i due numeri in cui vengono trasformate le classi 'male' e 'female'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding per 'Embarked'\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Inizializzazione dell'encoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Slezioniamo la variabile categorica da codificare\n",
    "embarked_encoded = encoder.fit_transform(df[['Embarked']])\n",
    "\n",
    "# Convertiamo i dati codificati in un DataFrame con nomi delle colonne significativi\n",
    "embarked_encoded_df = pd.DataFrame(embarked_encoded, columns=encoder.get_feature_names_out(['Embarked']))\n",
    "\n",
    "# Aggiungiamo le colonne codificate nel DataFrame originale\n",
    "df = pd.concat([df, embarked_encoded_df], axis=1)\n",
    "\n",
    "# Eliminiamo la colonna originale 'Embarked' dal dataset\n",
    "df = df.drop('Embarked', axis=1)\n",
    "\n",
    "# Mostriamo il DataFrame aggiornato\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> <br>\n",
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questa sezione utilizzeremo dei metodi di visualizzazione dei dati per continuare ad analizzare le caratteristiche del dataset. \n",
    "In particolare dovremo:\n",
    "- plottare la correlation heatmap per valutare la correlazione tra le diverse variabili\n",
    "- studiare come sono distribuite le diverse variabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stampiamo la correlation heatmap per valutare la correlazione tra le variabili\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distribuzione delle variabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Com'è distribuito il numero di sopravvissuti in base al sesso?\n",
    "df.groupby(['Sex', 'Survived'])['Survived'].count() # Usa groupby sulle colonne 'Sex' e 'Survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizziamo il risultato precedente\n",
    "sns.countplot(x='Sex',hue='Survived',data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Com'è distribuito il numero di sopravvissuti in base al lla classe del biglietto?\n",
    "df.groupby(['Pclass', 'Survived'])['Survived'].count() # Usa groupby sulle colonne 'Pclass' e 'Survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizziamo il risultato precedente\n",
    "sns.countplot(x='Pclass', hue='Survived', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambia i nomi delle variabili per visualizzare i diversi plot\n",
    "\n",
    "# Bar plot\n",
    "sns.countplot(x='Survived', data=df)\n",
    "plt.xlabel('Survival Status')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Survival Count')\n",
    "plt.show()\n",
    "\n",
    "# Histogram\n",
    "plt.hist(df['Age'], bins=10)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Age')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot\n",
    "plt.scatter(df['Age'], df['Fare'])\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Fare')\n",
    "plt.title('Age vs. Fare')\n",
    "plt.show()\n",
    "\n",
    "# Box plot\n",
    "sns.boxplot(x=df['Survived'], y=df['Fare'])\n",
    "plt.xlabel('Survival Status')\n",
    "plt.ylabel('Fare')\n",
    "plt.title('Survival Status vs. Fare')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Colonne da eliminare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonne da eliminare (non servono per il modello): 'PassengerId','Name','Ticket'\n",
    "columns_to_drop = [\"PassengerId\",\"Name\",\"Ticket\"]\n",
    "\n",
    "# Eliminiamo le colonne non necessarie al modello\n",
    "df_cleaned = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a> <br>\n",
    "\n",
    "## 3. Implementazione e valutazione del modello di Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questa sezione costruiremo e alleneremo il Decision tree Classifier (seguendo gli step illustrati nella presentazione). Infine valuteremo il modello ottenuto calcolando la matrice di confusione e le metriche ad essa associate.\n",
    "\n",
    "DecisionTreeClassifier (documentazione): https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiamo le variabili di input (X) e di output (y)\n",
    "# La colonna da prevedere è quella che si riferisce alla sopravvivenza o meno del passeggero ('Survived')\n",
    "X = df_cleaned.drop(columns=['...' ])\n",
    "y= df_cleaned['...' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividiamo i dati in training (80%) e test(20%)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controlliamo la dimensione del dataset di training e di test\n",
    "...\n",
    "...\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo il Decision Tree Classifier\n",
    "model = ... # Fissiamo il random_state (random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alleniamo il modello sui dati di training\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facciamo previsioni sui dati di test\n",
    "y_predict = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutiamo il modello\n",
    "\n",
    "# Stampiamo la matrice di confusione\n",
    "confusion = confusion_matrix(y_test, y_predict)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuratezza del modello\n",
    "accuracy = ...\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report dettagliato delle metriche\n",
    "report = ...\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dell'albero\n",
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(100,100))\n",
    "plot_tree(model, filled=True, feature_names=X_train.columns, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il modello Decision Tree permette di settare i valori per diversi parametri, ma quali sono i valori migliori? \n",
    "**GridSearch** che è un metodo per trovare automaticamente i migliori parametri di un modello. Invece di provare i valori manualmente, **GridSearchCV** testa tutte le combinazioni possibili di parametri e sceglie quella che dà le migliori prestazioni, basandosi su una metrica di valutazione (es. R² o RMSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_valid_scores = {}\n",
    "\n",
    "# Definiamo i valori possibili per la profondità massima dell'albero\n",
    "parameters = {\n",
    "    \"max_depth\": [3, 5, 7, 9, 11, 13],\n",
    "}\n",
    "\n",
    "model_desicion_tree = DecisionTreeClassifier(\n",
    "    random_state=123,\n",
    "    class_weight='balanced', # Bilancia automaticamente le classi se sono sbilanciate\n",
    ")\n",
    "\n",
    "model_desicion_tree = GridSearchCV(\n",
    "    model_desicion_tree, # Modello da ottimizzare\n",
    "    parameters, # Dizionario dei parametri da testare\n",
    "    cv=5, # Numero di suddivisioni per la cross-validation (5-fold CV)\n",
    "    scoring='accuracy', # Metrica di valutazione da ottimizzare\n",
    ")\n",
    "\n",
    "model_desicion_tree.fit(X_train, y_train)\n",
    "\n",
    "print(f'Migliore combinazione di parametri trovati {model_desicion_tree.best_params_}')\n",
    "print(\n",
    "    f'Media delle accuratezze ottenuta con la cross-validation per il miglior modello: ' + \\\n",
    "    f'{model_desicion_tree.best_score_:.3f}'\n",
    ")\n",
    "cross_valid_scores['desicion_tree'] = model_desicion_tree.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a> <br>\n",
    "\n",
    "## 4. Altri modelli di classificazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questa sezione testremo dei modelli di classificazione alternativi al Decision Tree\n",
    "- Random Forest Classifier\n",
    "- Logistic Regression\n",
    "\n",
    "*Random Forest Classifier*: È un modello di machine learning basato su più alberi decisionali. Ogni albero fa una previsione e la classe finale viene scelta con una votazione della maggioranza, ovvero la classe che ottiene il maggior numero di \"voti\" da parte degli alberi viene scelta come previsione del modello.\n",
    "\n",
    "*Logistic Regression*: Nonostante il nome, è un modello di classificazione, non di regressione. Pprevede la probabilità che un'osservazione appartenga a una certa classe (es. 0 o 1). È semplice, veloce e adatto per problemi di classificazione binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo il modello di Random Forest Classifier\n",
    "rf =...\n",
    "\n",
    "# Alleniamo il modello sui dati di training\n",
    "...\n",
    "\n",
    "# Facciamo previsioni sui dati di test\n",
    "rf_pred = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutiamo il modello\n",
    "\n",
    "# Stampiamo la matrice di confusione\n",
    "confusion = confusion_matrix(y_test, rf_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuratezza del modello\n",
    "accuracy = ...\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report dettagliato delle metriche\n",
    "report = ...\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo il modello di LogisticRegression\n",
    "logreg = ...\n",
    "\n",
    "# Alleniamo il modello su dati di training\n",
    "...\n",
    "\n",
    "# Facciamo previsioni sui dati di test\n",
    "logreg_pred = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutiamo il modello\n",
    "\n",
    "# Stampiamo la matrice di confusione\n",
    "confusion = confusion_matrix(y_test, logreg_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuratezza del modello\n",
    "accuracy = ...\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report dettagliato delle metriche\n",
    "report = ...\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domande"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Qual è il modello con l'accuratezza migliore?\n",
    "- Cosa succederebbe se invece di dividere il dataset in training set e test in modo randomico prendessimo come training set solo i passeggeri maschi e come test set solo le passeggere femmine?\n",
    "- Tra i parametri che possono essere scelti in un modello ad Albero Decisionale c'è la profondità dell'albero, ovvero quanti livelli (o nodi) dell'albero verranno considerati. Cosa potrebbe succedere se considerassimo un numero troppoo elevato di nodi? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
