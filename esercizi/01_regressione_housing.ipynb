{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California Housing Prices - Regressione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo notebook utilizzeremo una versione ridotta e leggermente modificata del dataset `California Housing Prices`. Il dataset contiene le caratteristiche delle case presenti in un determinato distretto della California e alcune statistiche riassuntive basate sul censimento statunitense del 1990. Ogni riga contiene le informazioni per uno specifico isolato residenziale (*block group*). \n",
    "\n",
    "Utilizzeremo questo dataset per sviluppare un modello di **regressione**, che ci permetterà di stimare il **prezzo mediano delle case** (*medianHouseValue*) in un certo isolato in base alle altre variabili socio-economiche e geografiche disponibili nel dataset. \n",
    "\n",
    "Dopo una prima parte di pre-processing dei dati, vedremo come implementare un modello di regressione lineare e faremo un confronto con altri modelli di regressione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a> <br>\n",
    "\n",
    "# Indice\n",
    "1. [Pre-processing dei dati](#1)\n",
    "2. [Exploratory Data Analysis](#2)\n",
    "3. [Implementazione e valutazione del modello di Regressione Lineare](#3)\n",
    "4. [Altri modelli di regressione](#4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> <br>\n",
    "## 1. Pre-processing dei dati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo step fondamentale prima di applicare un modello di Machine Learning è quello di studiare le caratteristiche principali dei dati per renderli utilizzabili dal modello che sceglieremo. In questa sezione, metteremo in pratica le tecniche viste nelle precedenti lezioni per analizzare il dataset, in particolare dovremo:\n",
    "- caricare il dataset\n",
    "- estrarre le prime descrizioni generali (dimensione, tipo di dati, variabili, ...)\n",
    "- gestire i valori mancanti\n",
    "- gestire variabili categoriche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Caricamento del dataset e descrizione generale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caricamento del dataset\n",
    "df = pd.read_csv('../data/housing_modified.csv')\n",
    "\n",
    "# Stampa le prime dieci righe\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Che dimensione ha il dataset? Quante righe e quante colonne ha?\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quali sono i nomi delle variabili presenti nel dataset?\n",
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il dataset contiene 10 variabili:\n",
    "\n",
    "1. **longitude** (longitudine): Coordinata geografica che indica la longitudine della posizione dell’isolato (valori più alti indicano una posizione più occidentale)\n",
    "\n",
    "2. **latitude** (latitudine): Coordinata geografica che indica la latitudine della posizione dell’isolato (valori più alti indicano una posizione più settentrionale)\n",
    "\n",
    "3. **housing_median_age** (età mediana delle abitazioni): Indica l’età mediana degli edifici presenti nell'isolato; valori più bassi indicano edifici più recenti\n",
    "\n",
    "4. **total_rooms** (numero totale di stanze): Totale delle stanze presenti in tutte le abitazioni dell’isolato\n",
    "\n",
    "5. **total_bedrooms** (numero totale di camere da letto): Totale delle camere da letto presenti nell’isolato\n",
    "\n",
    "6. **population** (popolazione): Numero totale di persone che risiedono nell’isolato\n",
    "\n",
    "7. **households** (unità abitative): Numero totale di famiglie o unità abitative nell’isolato\n",
    "\n",
    "8. **median_income** (reddito mediano): Indica il reddito mediano delle famiglie in un isolato, espresso in decine di migliaia di dollari (es. un valore di 5 equivale a 50.000$ annui)\n",
    "\n",
    "9. **median_house_value** (valore mediano delle case): Indica il valore mediano delle abitazioni in un isolato, espresso in dollari. Questa è la variabile target che vogliamo prevedere con la regressione lineare\n",
    "\n",
    "10. **ocean_proximity** (vicinanza all’oceano): Variabile categorica che descrive la posizione geografica dell’isolato rispetto alla costa. Può assumere i seguenti valori: \"NEAR OCEAN\" (vicino all’oceano), \"INLAND\" (nell’entroterra), \"NEAR BAY\" (vicino a una baia), \"<1H OCEAN\" (a meno di un’ora dall’oceano), \"ISLAND\" (situato su un’isola)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alcune informazioni importanti sul dataset (possiamo usare il metodo .info())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipo di dato in ogni colonna\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caratteristiche statistiche principali per le variabili numeriche\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Valori mancanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quanti valori nulli ci sono in ogni colonna?\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Come gestiamo i valori nulli?\n",
    "# Ci sono vari metodi per gestire i dati mancanti: possiamo eliminare dal dataset le righe corrispondenti, sostituirli con un valore medio o con il valore mediano, ...\n",
    "# In questo caso, siccome le righe che contengono i valori mancanti per 'total_bedrooms' sono solo 3 possiamo\n",
    "# decidere di eliminare direttamente le righe corrispondenti\n",
    "df.dropna(inplace=True) # Eliminiamo le righe che hanno almeno un valore nullo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controlliamo che l'operazione sia andata a buon fine\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controlliamo se ci sono duplicati in seguito alla nostra operazione e in caso affermativo li rimuoviamo\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Variabili categoriche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizziamo la colonna ocean_proximity contando il numero di osservazioni per ogni classe\n",
    "ocean_values = df[\"ocean_proximity\"].value_counts() # Inserire il nome della colonna di cui vogliamo analizzarei valori\n",
    "ocean_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trasformiamo la variabile categorica 'ocean_proximity' in variabile ordinale\n",
    "# Ricorda: una variabile ordinale è una variabile che assume valori categorici che però possono essere ordinati \n",
    "# (ad esempio una variabile 'Titolo di studio' con tre modalità disposte in ordine crescente: licenza media inferiore, diploma e laurea)\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Inizializzare l'OrdinalEncoder\n",
    "encoder = OrdinalEncoder(categories=[['ISLAND','NEAR OCEAN', 'NEAR BAY','<1H OCEAN', 'INLAND']])\n",
    "\n",
    "# Selezionare la variabile da trasformare\n",
    "ocean_proximity_encoded = encoder.fit_transform(df[['ocean_proximity']])\n",
    "\n",
    "# Convertire la colonna del DataFrame originario con i dati encoded\n",
    "df['ocean_proximity'] = ocean_proximity_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stampare il DataFrame aggiornato\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> <br>\n",
    "\n",
    "## 2. Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questa sezione utilizzeremo dei metodi di visualizzazione dei dati per continuare ad analizzare le caratteristiche del dataset. \n",
    "In particolare dovremo:\n",
    "- plottare la correlation heatmap per valutare la correlazione tra le diverse variabili\n",
    "- studiare le distribuzioni delle diverse variabili\n",
    "- gestire gli outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Correlazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stampiamo la correlation heatmap per valutare la correlazione tra le variabili\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distribuzioni delle variabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plottiamo la distribuzione geografica degli isolati. In quali zone le case hanno un prezzo più alto?\n",
    "df.plot(\n",
    "    kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
    "    s=df[\"population\"] / 100, label=\"population\", figsize=(15, 8),\n",
    "    c=\"median_house_value\",  colorbar=True\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Studiamo la distribuzione delle variabili presenti nel dataset\n",
    "df.hist(bins=25,figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a> <br>\n",
    "\n",
    "## 3. Implementazione e valutazione del modello di Regressione Lineare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questa sezione costruiremo e alleneremo il modello di regressione lineare (seguendo gli step illustrati nella presentazione). Infine valuteremo il modello ottenuto calcolando diverse metriche.\n",
    "\n",
    "LinearRegression (documentazione): https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error , mean_absolute_percentage_error , mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiamo le variabili di input (X) e di output (y)\n",
    "# Il nome della colonna da prevedere è il prezzo medio delle case in un isolato ('median_house_value')\n",
    "X = df.drop(columns=['...' ])\n",
    "y= df['...' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividiamo i dati in training (80%) e test(20%)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controlliamo la dimensione del dataset di training e di test\n",
    "...\n",
    "...\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizziamo i dati\n",
    "ro_scaler=RobustScaler()\n",
    "X_train=ro_scaler.fit_transform(X_train)\n",
    "X_test=ro_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo il modello di Regressione Lineare\n",
    "model = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alleniamo il modello sui dati di training\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facciamo previsioni sui dati di test\n",
    "y_predict = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutiamo il modello\n",
    "\n",
    "# calcoliamo le diverse metriche (R2, Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), Mean Absolupte Percentage Error (MAPE))\n",
    "r_squared = r2_score(... , ...)\n",
    "mse = mean_squared_error(..., ...)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(...,...)\n",
    "mape = mean_absolute_percentage_error(... , ...) # Misura l'errore medio in percentuale rispetto ai valori reali\n",
    "\n",
    "print('R squared (R2):',r_squared)\n",
    "print(f'Mean Squared Error (MSE):{mse}')\n",
    "print(f'Root Mean Squared Error (RMSE):{rmse}')\n",
    "print(f'Mean Absolute Error (MAE):{mae}')\n",
    "print(\"Mean  absolute precentage error of linear regression : \",mape*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plottiamo i valori reali vs i prezzi previsti. Se il modello non facesse errori dove dovrebbero essere tutti i punti?\n",
    "plt.scatter(np.array(y_test), y_predict)\n",
    "plt.plot(np.array(y_test),np.array(y_test),color='red')\n",
    "plt.xlabel(\"Prezzi reali delle case\")\n",
    "plt.ylabel(\"Prezzi previsti\")\n",
    "plt.title(\"Risultati Regressione Lineare: Prezzi reali vs Previsti\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a> <br>\n",
    "\n",
    "## 4. Altri modelli di regressione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questa sezione vedremo altri modelli di regressione e confronteremo gli errori con quelli ottenuti con il modello di regressione lineare. I modelli che vedremo saranno:\n",
    "- Ridge regression\n",
    "- Lasso regression\n",
    "- XGBoost Regressor\n",
    "\n",
    "*Ridge e Lasso Regression*\n",
    "Ridge Regression e Lasso Regression sono due versioni della regressione lineare che aggiungono una penalizzazione per evitare modelli troppo complessi (overfitting).\n",
    "\n",
    "*XGBoost Regressor*\n",
    "XGBoost Regressor è un modello avanzato basato su Gradient Boosting, che crea tanti piccoli alberi decisionali e li migliora passo dopo passo, correggendo gli errori fatti dai precedenti. È veloce e gestisce bene i dati con outlier o valori mancanti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo il modello di Ridge Regression\n",
    "ridge = Ridge(alpha=100, random_state=42)  # Prova con diversi valori di alpha\n",
    "\n",
    "# Alleniamo il modello sui dati di training\n",
    "...\n",
    "\n",
    "# Facciamo previsioni sui dati di test\n",
    "ridge_pred = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutiamo il modello di Ridge Regression\n",
    "r_squared_ridge = r2_score(y_test , ridge_pred)\n",
    "mse_ridge = mean_squared_error(y_test, ridge_pred)\n",
    "rmse_ridge = np.sqrt(mse_ridge)\n",
    "mae_ridge = mean_absolute_error(y_test,ridge_pred)\n",
    "mape_ridge = mean_absolute_percentage_error(y_test , ridge_pred)\n",
    "\n",
    "print('R squared of linear regression :',r_squared_ridge)\n",
    "print(f'Mean Squared Error (MSE):{mse_ridge}')\n",
    "print(f'Root Mean Squared Error (RMSE):{rmse_ridge}')\n",
    "print(f'Mean Absolute Error (MAE):{mae_ridge}')\n",
    "print(\"Mean  absolute precentage error of linear regression : \",mape_ridge*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo il modello di Lasso Regression\n",
    "lasso = Lasso(alpha=100, random_state=42)\n",
    "\n",
    "# Alleniamo il modello sui dati di training\n",
    "...\n",
    "\n",
    "# Facciamo previsioni sui dati di test\n",
    "lasso_pred = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared_lasso = r2_score(y_test , lasso_pred)\n",
    "mse_lasso = mean_squared_error(y_test, lasso_pred)\n",
    "rmse_lasso = np.sqrt(mse_lasso)\n",
    "mae_lasso = mean_absolute_error(y_test,lasso_pred)\n",
    "mape_lasso = mean_absolute_percentage_error(y_test , lasso_pred)\n",
    "\n",
    "print('R squared of linear regression :',r_squared_lasso)\n",
    "print(f'Mean Squared Error (MSE):{mse}')\n",
    "print(f'Root Mean Squared Error (RMSE):{rmse}')\n",
    "print(f'Mean Absolute Error (MAE):{mae}')\n",
    "print(\"Mean  absolute precentage error of linear regression : \",mape_lasso*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo il modello di XGBoost Regressor\n",
    "xgb = XGBRegressor(n_estimators=80, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Alleniamo il modello sui dati di training\n",
    "...\n",
    "\n",
    "# Facciamo previsioni sui dati di test\n",
    "xgb_pred = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared_xgb = r2_score(y_test , xgb_pred)\n",
    "mse_xgb = mean_squared_error(y_test, xgb_pred)\n",
    "rmse_xgb = np.sqrt(mse_xgb)\n",
    "mae_xgb = mean_absolute_error(y_test,xgb_pred)\n",
    "mape_xgb = mean_absolute_percentage_error(y_test , xgb_pred)\n",
    "\n",
    "print('R squared (R2) :',r_squared_lasso)\n",
    "print(f'Mean Squared Error (MSE):{mse_xgb}')\n",
    "print(f'Root Mean Squared Error (RMSE):{rmse_xgb}')\n",
    "print(f'Mean Absolute Error (MAE):{mae_xgb}')\n",
    "print(\"Mean  absolute precentage error of linear regression : \",mape_xgb*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qual è il modello migliore?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confrontiamo gli errori ottenuti con i diversi modelli\n",
    "\n",
    "# Creiamo un dizionario con gli errori ottenuti dai diversi modelli\n",
    "data = {\n",
    "    \"Metrica\": [\n",
    "        \"Linear Regression\",\n",
    "        \"Ridge Regression\",\n",
    "        \"Lasso Regression\",\n",
    "        \"XGBoost Regressor\"\n",
    "    ],\n",
    "    \"R²\": [r_squared, r_squared_ridge, r_squared_lasso, r_squared_xgb], # più il valore è vicino a 1, migliore è il modello\n",
    "    \"RMSE\": [rmse, rmse_ridge, rmse_lasso, rmse_xgb],\n",
    "    \"MAE\": [mae, mae_ridge, mae_lasso, mae_xgb],\n",
    "    \"MAPE\": [f\"{mape*100}%\", f\"{mape_ridge*100}%\", f\"{mape_lasso*100}%\", f\"{mape_xgb*100}%\"]\n",
    "}\n",
    "\n",
    "# Creiamo il DataFrame\n",
    "df = pd.DataFrame(data).round(2)\n",
    "\n",
    "# Stampiamo la tabella con un formato leggibile\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.array(y_test), xgb_pred)\n",
    "plt.plot(np.array(y_test),np.array(y_test),color='red')\n",
    "plt.xlabel(\"Prezzi reali delle case\")\n",
    "plt.ylabel(\"Prezzi previsti\")\n",
    "plt.title(\"Risultati Regressione Lineare: Prezzi reali vs Previsti\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
